Perfect — here’s your fully updated **root directory README** for the **MLOps Gun Detection** project, following your conventions:

✅ No horizontal rules
✅ Includes `custom_exception.py` and `logger.py` in `src/`
✅ Uses your standard project setup structure and tone

---

# 🏗️ **Initial Project Setup — MLOps Gun Detection**

This branch establishes the **foundational structure** for the **MLOps Gun Detection** project.
It sets up a **modular Python codebase** under `src/` and `pipeline/`, initialises dependency management with **`uv`**, and prepares the repository for the first workflow stage — **`01_data_ingestion`**, which will retrieve image data from **Kaggle via KaggleHub** for model development and training.

## 🗂️ **Project Structure**

```text
mlops-gun-detection/
├── .venv/                     # 🧩 Local virtual environment (created by uv)
├── config/                    # ⚙️ Configuration files and environment settings
│   ├── __init__.py
├── src/                       # 🧠 Core utilities and helper modules
│   ├── __init__.py
│   ├── custom_exception.py     # Unified and detailed exception handling
│   └── logger.py               # Centralised logging configuration
├── .gitignore                 # 🚫 Git ignore rules
├── pyproject.toml             # ⚙️ Project metadata and uv configuration
├── requirements.txt           # 📦 Python dependencies
├── uv.lock                    # 🔒 Dependency lock file (auto-generated by uv)
└── README.md                  # 📖 Project documentation (you are here)
```

> 💡 **Note:** The `.venv/` directory is ignored by Git and should not be committed.

## ⚙️ **Setup Process**

The following steps describe how this foundational environment and folder structure were created.

### 1️⃣ Create the Project Structure

Directories were created to separate **core utilities**, **pipeline logic**, and **configuration files**, ensuring the project remains modular and maintainable.

```bash
mkdir -p pipeline src
touch pipeline/__init__.py src/__init__.py
```

Two essential modules were added to `src/`:

* `custom_exception.py` — provides a detailed, consistent exception-handling mechanism.
* `logger.py` — defines a central logging configuration used across all modules.

### 2️⃣ Create and Activate the Virtual Environment (with `uv`)

This project uses [`uv`](https://github.com/astral-sh/uv) — a modern, high-performance Python package manager.

Create a Python 3.12 virtual environment:

```bash
uv venv --python 3.12
```

Activate the environment:

* **Windows (cmd):**

  ```cmd
  .\.venv\Scripts\activate
  ```
* **PowerShell:**

  ```powershell
  .\.venv\Scripts\Activate.ps1
  ```
* **macOS / Linux:**

  ```bash
  source .venv/bin/activate
  ```

When active, `(.venv)` will appear in your terminal prompt.

### 3️⃣ Define Project Dependencies

A minimal `requirements.txt` file was created to support the initial setup.
This list will expand as we add **OpenCV processing**, **KaggleHub ingestion**, and **model training** capabilities.

Example:

```text
opencv-python
numpy
pandas
matplotlib
kagglehub
```

Install dependencies and generate a lock file for reproducibility:

```bash
uv pip install -r requirements.txt
uv lock
```

### 4️⃣ Define Project Metadata

A simple `pyproject.toml` ensures consistent environment configuration and dependency management.

Example:

```toml
[project]
name = "mlops-gun-detection"
version = "0.1.0"
description = "An MLOps pipeline for detecting guns in images using OpenCV."
readme = "README.md"
requires-python = ">=3.12"

[tool.uv]
dev-dependencies = []
```

The `uv.lock` file records exact dependency versions for consistent builds.

### 5️⃣ Add Core Source and Pipeline Packages

The main packages `src/` and `pipeline/` have been initialised.
Future stages will expand these directories with modules for data ingestion, preprocessing, model training, and deployment.

| Folder      | Purpose                                                             |
| ----------- | ------------------------------------------------------------------- |
| `src/`      | Core utility code (logging, exceptions, and helper functions).      |
| `pipeline/` | Workflow and orchestration logic for ingestion and model pipelines. |

## 🚀 **Next Steps**

The next workflow stage — **`01_data_ingestion`** — will focus on:

* Accessing datasets from **Kaggle** using **KaggleHub**.
* Downloading and verifying **gun image datasets** for detection training.

Subsequent stages will include:

* 🧠 Feature extraction and bounding box generation using OpenCV.
* 🔍 Model training, evaluation, and inference.
* ☁️ Deployment and monitoring through a modular MLOps workflow.

✅ **In summary:**
This setup provides a clean, reproducible foundation for the **MLOps Gun Detection** pipeline — establishing reliable logging, robust error handling, and a scalable structure ready for the first data ingestion stage.
